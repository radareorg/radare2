return strdup (
"=PC	rip\n"
"=SP	rsp\n"
"=BP	rbp\n"
"=A0	rax\n"
"=A1	rbx\n"
"=A2	rcx\n"
"=A3	rdx\n"
"# no profile defined for x86-64\n"
"gpr	riz	.64	?	0\n"
"gpr	r15	.64	0	0\n"
"gpr	r15d	.32	0	0\n"
"gpr	r15w	.16	0	0\n"
"gpr	r15b	.8	0	0\n"
"gpr	r14	.64	8	0\n"
"gpr	r14d	.32	8	0\n"
"gpr	r14w	.16	8	0\n"
"gpr	r14b	.8	8	0\n"
"gpr	r13	.64	16	0\n"
"gpr	r13d	.32	16	0\n"
"gpr	r13w	.16	16	0\n"
"gpr	r13b	.8	16	0\n"
"gpr	r12	.64	24	0\n"
"gpr	r12d	.32	24	0\n"
"gpr	r12w	.16	24	0\n"
"gpr	r12b	.8	24	0\n"
"gpr	r11	.64	32	0\n"
"gpr	r11d	.32	32	0\n"
"gpr	r11w	.16	32	0\n"
"gpr	r11b	.8	32	0\n"
"gpr	r10	.64	40	0\n"
"gpr	r10d	.32	40	0\n"
"gpr	r10w	.16	40	0\n"
"gpr	r10b	.8	40	0\n"
"gpr	r9	.64	48	0\n"
"gpr	r9d	.32	48	0\n"
"gpr	r9w	.16	48	0\n"
"gpr	r9b	.8	48	0\n"
"gpr	r8	.64	56	0\n"
"gpr	r8d	.32	56	0\n"
"gpr	r8w	.16	56	0\n"
"gpr	r8b	.8	56	0\n"
"gpr	rdi	.64	64	0\n"
"gpr	edi	.32	64	0\n"
"gpr	di	.16	64	0\n"
"gpr	dil	.8	64	0\n"
"gpr	rsi	.64	72	0\n"
"gpr	esi	.32	72	0\n"
"gpr	si	.16	72	0\n"
"gpr	sil	.8	72	0\n"
"gpr	rbp	.64	80	0\n"
"gpr	ebp	.32	80	0\n"
"gpr	bp	.16	80	0\n"
"gpr	bpl	.8	80	0\n"
"gpr	rbx	.64	88	0\n"
"gpr	ebx	.32	88	0\n"
"gpr	bx	.16	88	0\n"
"gpr	bl	.8	88	0\n"
"gpr	rdx	.64	96	0\n"
"gpr	edx	.32	96	0\n"
"gpr	dx	.16	96	0\n"
"gpr	dl	.8	96	0\n"
"gpr	rcx	.64	104	0\n"
"gpr	ecx	.32	104	0\n"
"gpr	cx	.16	104	0\n"
"gpr	cl	.8	104	0\n"
"gpr	rax	.64	112	0\n"
"gpr	eax	.32	112	0\n"
"gpr	ax	.16	112	0\n"
"gpr	al	.8	112	0\n"
"gpr	trapno	.64	120	0\n"
"gpr	err	.64	128	0\n"
"gpr	rip	.64	136	0\n"
"seg	cs	.64	144	0\n"
"gpr	rflags	.64	152	0	c1p.a.zstido.n.rv\n"
"flg	eflags	.32	152	0	c1p.a.zstido.n.rv\n"
"gpr	rsp	.64	160	0\n"
"seg	ss	.64	168	0\n"
"flg	cf	.1	.1216	0	carry\n"
"flg	pf	.1	.1218	0	parity\n"
"flg	af	.1	.1220	0	adjust\n"
"flg	zf	.1	.1222	0	zero\n"
"flg	sf	.1	.1223	0	sign\n"
"flg	tf	.1	.1224	0	trap\n"
"flg	if	.1	.1225	0	interrupt\n"
"flg	df	.1	.1226	0	direction\n"
"flg	of	.1	.1227	0	overflow\n"
"fpu	cwd	.16	0	0\n"
"fpu	swd	.16	2	0\n"
"fpu	ftw	.16	4	0\n"
"fpu	fop	.16	6	0\n"
"fpu	frip	.64	8	0\n"
"fpu	frdp	.64	16	0\n"
"fpu	mxcsr	.32	24	0\n"
"fpu	mxcr_mask	.32	28	0\n"

"fpu	st0	.80	32	0\n"
"fpu	st1	.80	48	0\n"
"fpu	st2	.80	64	0\n"
"fpu	st3	.80	80	0\n"
"fpu	st4	.80	96	0\n"
"fpu	st5	.80	112	0\n"
"fpu	st6	.80	128	0\n"
"fpu	st7	.80	144	0\n"

"vec64@fpu	mm0 .64 32	8\n"
"vec64@fpu	mm1 .64 48	8\n"
"vec64@fpu	mm2 .64 64	8\n"
"vec64@fpu	mm3 .64 80	8\n"
"vec64@fpu	mm4 .64 96	8\n"
"vec64@fpu	mm5 .64 112	8\n"
"vec64@fpu	mm6 .64 128 8\n"
"vec64@fpu	mm7 .64 144 8\n"

"vec128@fpu    xmm0    .128	160 16\n"
"fpu		xmm0l	         .64	160	8\n"
"fpu		xmm0h	 .64	168	8\n"
"vec128@fpu    xmm1    .128	176 16\n"
"fpu		xmm1l	         .64	176	8\n"
"fpu		xmm1h	 .64	184	8\n"
"vec128@fpu    xmm2    .128	192 16\n"
"fpu		xmm2l	         .64	192	8\n"
"fpu		xmm2h	 .64	200	8\n"
"vec128@fpu    xmm3    .128	208 16\n"
"fpu		xmm3l	         .64	208	8\n"
"fpu		xmm3h	.64		216	8\n"
"vec128@fpu    xmm4    .128	224 16\n"
"fpu		xmm4l	         .64	224	8\n"
"fpu		xmm4h	 .64	232	8\n"
"vec128@fpu    xmm5    .128	240 16\n"
"fpu		xmm5l	         .64	240	8\n"
"fpu		xmm5h	 .64	248	8\n"
"vec128@fpu    xmm6    .128	256 16\n"
"fpu		xmm6l	         .64	256	8\n"
"fpu		xmm6h	 .64	264	8\n"
"vec128@fpu    xmm7    .128	272 16\n"
"fpu		xmm7l	         .64	272	8\n"
"fpu		xmm7h	 .64	280	8\n"
"vec128@fpu    xmm8    .128	288 16\n"
"fpu		xmm8l	         .64	288	8\n"
"fpu		xmm8h	 .64	296	8\n"
"vec128@fpu    xmm9    .128	304 16\n"
"fpu		xmm9l	         .64	304	8\n"
"fpu		xmm9h	 .64	312	8\n"
"vec128@fpu    xmm10   .128	320 16\n"
"fpu		xmm10l	 .64	320	8\n"
"fpu		xmm10h	 .64	328	8\n"
"vec128@fpu    xmm11   .128	336 16\n"
"fpu		xmm11l	 .64	336	8\n"
"fpu		xmm11h	 .64	344	8\n"
"vec128@fpu    xmm12   .128	352 16\n"
"fpu		xmm12l	   .64	352	8\n"
"fpu		xmm12h	   .64	360	8\n"
"vec128@fpu    xmm13   .128	368 16\n"
"fpu		xmm13l	  .64	368	8\n"
"fpu		xmm13h	  .64	376	8\n"
"vec128@fpu    xmm14   .128	384 16\n"
"fpu		xmm14l	   .64	384	8\n"
"fpu		xmm14h	   .64	392	8\n"
"vec128@fpu    xmm15   .128	400 16\n"
"fpu		xmm15l	   .64	400	8\n"
"fpu		xmm15h	   .64	408	8\n"
"fpu	x64	.64	416	0\n"
);
